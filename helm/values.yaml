# OpenWebUI Platform Configuration
# Production-ready Kubernetes deployment with GraphRAG and MCP

# Global configuration
global:
  imageRegistry: ""
  imagePullSecrets: []
  storageClass: ""
  
# OpenWebUI Frontend Application
openwebui:
  enabled: true
  replicaCount: 2
  
  image:
    repository: ghcr.io/open-webui/open-webui
    tag: "main"
    pullPolicy: IfNotPresent
  
  service:
    type: ClusterIP
    port: 8080
    targetPort: 8080
  
  resources:
    limits:
      cpu: 2
      memory: 4Gi
    requests:
      cpu: 500m
      memory: 1Gi
  
  env:
    WEBUI_SECRET_KEY: "your-production-secret-key"
    DATABASE_URL: "postgresql://postgres:postgres@postgresql:5432/openwebui"
    REDIS_URL: "redis://redis-master:6379"
    VECTOR_DB_URL: "http://qdrant:6333"
    GRAPH_DB_URL: "bolt://neo4j:7687"
    ENABLE_GRAPHRAG: "true"
    ENABLE_MCP: "true"
  
  persistence:
    enabled: true
    storageClass: ""
    size: 10Gi
    
  autoscaling:
    enabled: true
    minReplicas: 2
    maxReplicas: 10
    targetCPUUtilizationPercentage: 70
    targetMemoryUtilizationPercentage: 80

# LightLLM Model Serving (replacing Ollama for production)
lightllm:
  enabled: true
  replicaCount: 1
  
  image:
    repository: modelscope/lightllm
    tag: "latest"
    pullPolicy: IfNotPresent
  
  service:
    type: ClusterIP
    port: 8000
    targetPort: 8000
  
  resources:
    limits:
      cpu: 8
      memory: 32Gi
      nvidia.com/gpu: 1
    requests:
      cpu: 4
      memory: 16Gi
      nvidia.com/gpu: 1
  
  nodeSelector:
    accelerator: nvidia-gpu
  
  tolerations:
    - key: "nvidia.com/gpu"
      operator: "Exists"
      effect: "NoSchedule"
  
  persistence:
    enabled: true
    storageClass: ""
    size: 500Gi  # For storing multiple models
    
  models:
    - name: "llama2-7b"
      path: "/models/llama2-7b"
    - name: "codellama-13b"
      path: "/models/codellama-13b"

# GraphRAG Processing Services
graphrag:
  enabled: true
  
  # Document Processing Service
  processor:
    replicaCount: 2
    
    image:
      repository: openwebui/graphrag-processor
      tag: "1.0.0"
      pullPolicy: IfNotPresent
    
    resources:
      limits:
        cpu: 4
        memory: 8Gi
      requests:
        cpu: 1
        memory: 2Gi
    
    autoscaling:
      enabled: true
      minReplicas: 2
      maxReplicas: 5
      targetCPUUtilizationPercentage: 80
  
  # Celery Workers for Async Processing
  workers:
    replicaCount: 3
    
    image:
      repository: openwebui/graphrag-worker
      tag: "1.0.0"
      pullPolicy: IfNotPresent
    
    resources:
      limits:
        cpu: 2
        memory: 4Gi
      requests:
        cpu: 500m
        memory: 1Gi
    
    autoscaling:
      enabled: true
      minReplicas: 3
      maxReplicas: 10
      targetCPUUtilizationPercentage: 75

# MCP Server Configuration
mcp:
  enabled: true
  replicaCount: 2
  
  image:
    repository: openwebui/mcp-server
    tag: "1.0.0"
    pullPolicy: IfNotPresent
  
  service:
    type: ClusterIP
    port: 9000
    targetPort: 9000
  
  resources:
    limits:
      cpu: 1
      memory: 2Gi
    requests:
      cpu: 250m
      memory: 512Mi
  
  autoscaling:
    enabled: true
    minReplicas: 2
    maxReplicas: 5
    targetCPUUtilizationPercentage: 70

# PostgreSQL Database
postgresql:
  enabled: true
  auth:
    postgresPassword: "postgres"
    database: "openwebui"
  
  primary:
    persistence:
      enabled: true
      size: 100Gi
    
    resources:
      limits:
        cpu: 4
        memory: 8Gi
      requests:
        cpu: 1
        memory: 2Gi
  
  readReplicas:
    replicaCount: 1
    persistence:
      enabled: true
      size: 100Gi
    
    resources:
      limits:
        cpu: 2
        memory: 4Gi
      requests:
        cpu: 500m
        memory: 1Gi

# Redis Cache
redis:
  enabled: true
  auth:
    enabled: false
  
  master:
    persistence:
      enabled: true
      size: 20Gi
    
    resources:
      limits:
        cpu: 2
        memory: 4Gi
      requests:
        cpu: 250m
        memory: 512Mi
  
  replica:
    replicaCount: 2
    persistence:
      enabled: true
      size: 20Gi
    
    resources:
      limits:
        cpu: 1
        memory: 2Gi
      requests:
        cpu: 125m
        memory: 256Mi

# Qdrant Vector Database
qdrant:
  enabled: true
  replicaCount: 1
  
  image:
    repository: qdrant/qdrant
    tag: "latest"
  
  service:
    type: ClusterIP
    port: 6333
  
  persistence:
    enabled: true
    size: 200Gi
  
  resources:
    limits:
      cpu: 4
      memory: 16Gi
    requests:
      cpu: 1
      memory: 4Gi
  
  config:
    cluster:
      enabled: false  # Enable for multi-node setup
    service:
      http_port: 6333
      grpc_port: 6334

# Neo4j Graph Database
neo4j:
  enabled: true
  
  neo4j:
    password: "password"
    edition: "community"
  
  volumes:
    data:
      mode: "defaultStorageClass"
      defaultStorageClass:
        requests:
          storage: 100Gi
  
  services:
    neo4j:
      ports:
        http: 7474
        https: 7473
        bolt: 7687
  
  config:
    dbms.memory.heap.initial_size: "1G"
    dbms.memory.heap.max_size: "8G"
    dbms.memory.pagecache.size: "4G"

# Nginx Ingress Controller
ingress:
  enabled: true
  className: "nginx"
  annotations:
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
  
  hosts:
    - host: ai-assistant.yourdomain.com
      paths:
        - path: /
          pathType: Prefix
          service:
            name: openwebui
            port: 8080
  
  tls:
    - secretName: ai-assistant-tls
      hosts:
        - ai-assistant.yourdomain.com

# Monitoring Configuration
monitoring:
  enabled: true
  
  prometheus:
    enabled: true
    server:
      persistentVolume:
        enabled: true
        size: 50Gi
      
      resources:
        limits:
          cpu: 2
          memory: 8Gi
        requests:
          cpu: 500m
          memory: 2Gi
  
  grafana:
    enabled: true
    persistence:
      enabled: true
      size: 10Gi
    
    resources:
      limits:
        cpu: 1
        memory: 2Gi
      requests:
        cpu: 250m
        memory: 512Mi
    
    adminPassword: "admin123"
    
    dashboardProviders:
      dashboardproviders.yaml:
        apiVersion: 1
        providers:
        - name: 'default'
          orgId: 1
          folder: ''
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/default

# Security Configuration
security:
  networkPolicies:
    enabled: true
  
  podSecurityPolicy:
    enabled: true
  
  rbac:
    create: true
  
  serviceAccount:
    create: true
    annotations: {}

# Backup Configuration
backup:
  enabled: true
  schedule: "0 2 * * *"  # Daily at 2 AM
  retention: "30d"
  
  s3:
    enabled: false
    bucket: ""
    region: ""
    accessKeyId: ""
    secretAccessKey: ""
  
  gcs:
    enabled: false
    bucket: ""
    serviceAccountKey: ""

# Elasticsearch for Full-Text Search (Optional)
elasticsearch:
  enabled: false
  replicas: 1
  
  persistence:
    enabled: true
    size: 100Gi
  
  resources:
    limits:
      cpu: 2
      memory: 4Gi
    requests:
      cpu: 500m
      memory: 2Gi